{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEak9mRa3qAFdmmoeoH+3H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"A6kHTCaX_qm_"},"outputs":[],"source":["%%capture\n","\n","# Библиотека с популярными сервисами распознавания речи\n","!pip install SpeechRecognition\n","\n","# Модуль метрики качества распознавания речи\n","!pip install jiwer\n","\n","# Кроссплатформенная open-source библиотека для обработки видео- и аудиофайлов\n","!pip install ffmpeg-python\n","\n","!pip install pyannote.audio\n","!pip install torch\n","!pip install torchaudio"]},{"cell_type":"code","source":["# Библиотека с популярными сервисами распознавания речи\n","import speech_recognition as sR\n","\n","import torch\n","from pyannote.audio import Pipeline\n","from pydub import AudioSegment\n","\n","# Модуль метрики качества распознавания речи\n","from jiwer import wer\n","\n","# Кроссплатформенная open-source библиотека для обработки видео- и аудиофайлов\n","import ffmpeg\n","\n","# Библиотека matplotlib\n","from matplotlib import pyplot as plt\n","\n","# Импортируем модули HTML и Audio чтобы обратиться к HTML для записи аудио с микрофона в ноутбуке colab\n","from IPython.display import HTML, Audio\n","\n","# Библиотека для запуска кода javascript\n","from google.colab.output import eval_js\n","\n","# Модуль для кодировки/раскодировки аудиозаписи(64-разрядный код)\n","from base64 import b64decode\n","\n","# Модуль для чтения WAV формата\n","from scipy.io.wavfile import read as wav_read\n","import scipy.io.wavfile as wavfile\n","# Модуль для работы с бинарными данными\n","import io\n","\n","# Библиотека для работы со звуковой дорожкой\n","import scipy\n","\n","# Модуль для работы с каталогами\n","import os\n","\n","# Модуль для разбивки данных на обучающую и тестовую выборки\n","from sklearn.model_selection import train_test_split\n","\n","# Модуль для проигрывания аудио\n","import IPython.display as ipd\n","\n","# Загрузка датасетов из облака google\n","import gdown\n","\n","import numpy as np\n"],"metadata":{"id":"kgC1kJFqAXpp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def recognizeAudio(filename,\n","                   offset=None,\n","                   duration=None):\n","\n","  # Задаем путь к аудиофайлу\n","  AUDIO_FILE = os.path.join(filename)\n","\n","  # Создаем объект класса Recognizer\n","  r = sR.Recognizer()\n","\n","  # Считываем аудиофайл\n","  with sR.AudioFile(AUDIO_FILE) as source:\n","    audio = r.record(source,\n","                     offset=offset,\n","                     duration=duration)\n","\n","  # Запускаем распознавание\n","  return r.recognize_google(audio, language='ru')"],"metadata":{"id":"RYQNOvkrAcbx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def segment_audio(filename, auth_token):\n","    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=auth_token)\n","    diarization = pipeline({\"uri\": \"filename\", \"audio\": filename})\n","    segments = []\n","    for turn, _, speaker in diarization.itertracks(yield_label=True):\n","        segments.append((turn.start, turn.end, speaker))\n","    return segments"],"metadata":{"id":"uZrkh6X-Es0s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_segments(filename, segments):\n","    audio = AudioSegment.from_wav(filename)\n","    segment_files = []\n","    for i, (start, end, speaker) in enumerate(segments):\n","        segment = audio[start * 1000:end * 1000]\n","        segment_filename = f'segment_{i}.wav'\n","        segment.export(segment_filename, format=\"wav\")\n","        segment_files.append((segment_filename, speaker))\n","    return segment_files"],"metadata":{"id":"GJZja65mEurK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_audio(filename, auth_token):\n","    segments = segment_audio(filename, auth_token)\n","    segment_files = save_segments(filename, segments)\n","    results = {}\n","    for segment_file, speaker in segment_files:\n","        try:\n","            recognized_text = recognizeAudio(segment_file)\n","            if speaker not in results:\n","                results[speaker] = []\n","            results[speaker].append(recognized_text)\n","        except sR.UnknownValueError:\n","            print(f\"Could not understand segment for speaker {speaker}\")\n","        except sR.RequestError:\n","            print(f\"Could not request results for segment for speaker {speaker}\")\n","    return results"],"metadata":{"id":"Zsdzi815EyP5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AUDIO_HTML = \"\"\"\n","<script>                                                      // создаем тег <script>, сообщающий браузеру о том, что внутри находится исполняемый код JavaScript\n","var my_div = document.createElement(\"DIV\");                   // создаем новый элемент DIV(тег-контейнер для логического выделения блока документа)\n","var my_p = document.createElement(\"P\");                       // создаем новый элемент P(параграф для логической группировки текста)\n","var my_btn = document.createElement(\"BUTTON\");                // создаем новый элемент(кнопку) BUTTON\n","var t = document.createTextNode(\"Нажмите старт для записи\");  // создаем текстовое содержимое для кнопки\n","\n","my_btn.appendChild(t);                                        // добавляем текстовое содержимое элементу BUTTON\n","my_div.appendChild(my_btn);                                   // кнопку с текстом BUTTON добавляем в блок DIV\n","document.body.appendChild(my_div);                            // добавляем наш блок в элемент <body>(\"тело\", для хранения содержимого веб-страницы)\n","\n","var base64data = 0;                                           // будем использовать для аудиоданных метод кодирования информации в 64-разрядный код\n","var reader;                                                   // создаем переменную для чтения файла\n","var recorder, gumStream;                                      // объявляем переменные для записи данных/потока\n","var recordButton = my_btn;                                    // создаем переменную для кнопки записи аудио с микрофона\n","\n","var handleSuccess = function(stream) {                        // объявляем функцию для работы с потоками данных\n","  gumStream = stream;                                         // создаем переменную для потока\n","  var options = {\n","    mimeType : 'audio/webm;codecs=opus'                       // в опциях задаем медиа тип с аудиоформатом и кодеками\n","  };\n","  recorder = new MediaRecorder(stream);                       // создаем новый объект MediaRecorder, получающий медиапоток для записи.\n","                                                              // MediaRecorder - интерфейс MediaStream Recording API представляющий функциональность для простой записи медиа. Создается..\n","                                                              // ..с использованием MediaRecorder() конструктора.\n","  recorder.ondataavailable = function(e) {                    // вызываем обработчик dataavailable события, запускаемое по окончанию записи\n","    var url = URL.createObjectURL(e.data);                    // этим методом создаем DOMString(UTF-16 String), содержащий URL с указанием на объект e.data\n","    var preview = document.createElement('audio');            // создаем элемент-тег аудио\n","    preview.controls = true;                                  // активизируем элементы управления\n","    preview.src = url;                                        // берем в кач-ве исходных данных файл, содержащийся в записанной ранее URL\n","    document.body.appendChild(preview);                       // добавляем элемент аудио в <body>(\"тело\", для хранения содержимого веб-страницы)\n","\n","    reader = new FileReader();                                // создаем объект класса FileReader для чтения разных источников данных\n","    reader.readAsDataURL(e.data);                             // читаем содержимое указанного файла\n","    reader.onloadend = function() {                           // обработчик события, запускаемого после передачи данных\n","      base64data = reader.result;                             // записываем прочитанное содержимое в base64data\n","    }\n","  };\n","  recorder.start();  // начало записи медиа\n","  };\n","\n","// такой текст будет на кнопке BUTTON во время записи аудио\n","recordButton.innerText = \"Идёт запись... нажмите для остановки\";\n","\n","// запрос разрешения пользователя на доступ к устройству захвата аудио(микрофон), указываем True\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {                                  // функция опишет действия по завершению записи (после клика мышкой по кнопке \"Recording... press to stop\")\n","  if (recorder && recorder.state == \"recording\") {            // если рекордер находится в процессе записи\n","      recorder.stop();  // рекордер прерывается\n","      gumStream.getAudioTracks()[0].stop();                   // отключается запись и доступ к микрофону\n","      recordButton.innerText = \"Идёт сохранение записи...\"    // эта надпись(сохранение записи) отобразится на кнопке BUTTON\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {                                          // создаем функцию с задержкой вызова\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","\n","  // new Promise - конструкция для отложенных вычислений\n","  // setTimeout позволяет вызвать функцию один раз через определённый интервал времени\n","}\n","\n","var data = new Promise(resolve=>{\n","recordButton.onclick = ()=>{      // при нажатии левой кнопкой мыши на кнопку \"Recording... press to stop\"\n","toggleRecording()                 // вызывается функция завершения аудиозаписи\n","\n","sleep(2000).then(() => {          // и после задержки 2000мс(2 сек)\n","  resolve(base64data.toString())  // полученные данные из формата base64 преобразовываем в строку\n","\n","});\n","\n","}\n","});\n","\n","</script>\n","\"\"\""],"metadata":{"id":"FqdkNDePAeeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_audio():\n","\n","  display(HTML(AUDIO_HTML))              # С помощью модулей библиотеки IPython отображаем результат выполнения скрипта AUDIO_HTML\n","  data = eval_js(\"data\")                 # Данные на выходе запишем в data как результат выполнения javascript кода\n","  binary = b64decode(data.split(',')[1]) # Отсекаем ненужную информацию, оставляем только данные и декодируем\n","\n","  # Зададим параметры для конвертации\n","  process = (ffmpeg\n","    .input('pipe:0')                   # Pipe стандартного ввода\n","    .output('pipe:1', format='wav')    # Pipe стандартного вывода в формате wav\n","    .run_async(pipe_stdin=True,        # Подключение pipe к stdin\n","               pipe_stdout=True,       # Подключение pipe к stdout\n","               pipe_stderr=True,       # Подключение pipe к stderr\n","               quiet=True,             # Сокращение для настройки capture_stdout и capture_stderr\n","               overwrite_output=True)) # Перезаписать выходные файлы без запроса\n","\n","  # binary преобразуем в wav, с типичным для медиафайлов форматом RIFF\n","  output, err = process.communicate(input=binary)\n","\n","  # Размер заголовка секции RIFF - 8 байт, их ниже уберём из определения размера секции RIFF\n","  riff_chunk_size = len(output) - 8\n","\n","  # Разбиваем размер секции на четыре байта, которые запишем далее в b.\n","  q = riff_chunk_size\n","  b = []\n","  for i in range(4):        # Запустим цикл 4 раза\n","      q, r = divmod(q, 256) # Возьмем размер секции и вернем частное и остаток от деления на 256\n","      b.append(r)           # Каждый из остатков добавим в список\n","\n","  # Меняем байты c 4го по 7й вкл-но в output на b\n","  riff = output[:4] + bytes(b) + output[8:]\n","\n","  # Извлечём частоту дискретизации и полученный сигнал\n","  sr, audio = wav_read(io.BytesIO(riff))\n","\n","  return audio, sr # Функция вернет полученный сигнал и частоту дискретизации"],"metadata":{"id":"8UrZ3FhZAhLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auth_token = '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'"],"metadata":{"id":"zGKvyPFDSfAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["audio, sr = get_audio()\n","scipy.io.wavfile.write('recording1.wav', sr, audio)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":97},"id":"DxG8mjJoAkMY","executionInfo":{"status":"ok","timestamp":1721046690209,"user_tz":-180,"elapsed":20117,"user":{"displayName":"Андрей Носков","userId":"00660409203221693156"}},"outputId":"d5f2f241-709d-40dc-dbb9-9edcf3b91637"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script>                                                      // создаем тег <script>, сообщающий браузеру о том, что внутри находится исполняемый код JavaScript\n","var my_div = document.createElement(\"DIV\");                   // создаем новый элемент DIV(тег-контейнер для логического выделения блока документа)\n","var my_p = document.createElement(\"P\");                       // создаем новый элемент P(параграф для логической группировки текста)\n","var my_btn = document.createElement(\"BUTTON\");                // создаем новый элемент(кнопку) BUTTON\n","var t = document.createTextNode(\"Нажмите старт для записи\");  // создаем текстовое содержимое для кнопки\n","\n","my_btn.appendChild(t);                                        // добавляем текстовое содержимое элементу BUTTON\n","my_div.appendChild(my_btn);                                   // кнопку с текстом BUTTON добавляем в блок DIV\n","document.body.appendChild(my_div);                            // добавляем наш блок в элемент <body>(\"тело\", для хранения содержимого веб-страницы)\n","\n","var base64data = 0;                                           // будем использовать для аудиоданных метод кодирования информации в 64-разрядный код\n","var reader;                                                   // создаем переменную для чтения файла\n","var recorder, gumStream;                                      // объявляем переменные для записи данных/потока\n","var recordButton = my_btn;                                    // создаем переменную для кнопки записи аудио с микрофона\n","\n","var handleSuccess = function(stream) {                        // объявляем функцию для работы с потоками данных\n","  gumStream = stream;                                         // создаем переменную для потока\n","  var options = {\n","    mimeType : 'audio/webm;codecs=opus'                       // в опциях задаем медиа тип с аудиоформатом и кодеками\n","  };\n","  recorder = new MediaRecorder(stream);                       // создаем новый объект MediaRecorder, получающий медиапоток для записи.\n","                                                              // MediaRecorder - интерфейс MediaStream Recording API представляющий функциональность для простой записи медиа. Создается..\n","                                                              // ..с использованием MediaRecorder() конструктора.\n","  recorder.ondataavailable = function(e) {                    // вызываем обработчик dataavailable события, запускаемое по окончанию записи\n","    var url = URL.createObjectURL(e.data);                    // этим методом создаем DOMString(UTF-16 String), содержащий URL с указанием на объект e.data\n","    var preview = document.createElement('audio');            // создаем элемент-тег аудио\n","    preview.controls = true;                                  // активизируем элементы управления\n","    preview.src = url;                                        // берем в кач-ве исходных данных файл, содержащийся в записанной ранее URL\n","    document.body.appendChild(preview);                       // добавляем элемент аудио в <body>(\"тело\", для хранения содержимого веб-страницы)\n","\n","    reader = new FileReader();                                // создаем объект класса FileReader для чтения разных источников данных\n","    reader.readAsDataURL(e.data);                             // читаем содержимое указанного файла\n","    reader.onloadend = function() {                           // обработчик события, запускаемого после передачи данных\n","      base64data = reader.result;                             // записываем прочитанное содержимое в base64data\n","    }\n","  };\n","  recorder.start();  // начало записи медиа\n","  };\n","\n","// такой текст будет на кнопке BUTTON во время записи аудио\n","recordButton.innerText = \"Идёт запись... нажмите для остановки\";\n","\n","// запрос разрешения пользователя на доступ к устройству захвата аудио(микрофон), указываем True\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {                                  // функция опишет действия по завершению записи (после клика мышкой по кнопке \"Recording... press to stop\")\n","  if (recorder && recorder.state == \"recording\") {            // если рекордер находится в процессе записи\n","      recorder.stop();  // рекордер прерывается\n","      gumStream.getAudioTracks()[0].stop();                   // отключается запись и доступ к микрофону\n","      recordButton.innerText = \"Идёт сохранение записи...\"    // эта надпись(сохранение записи) отобразится на кнопке BUTTON\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {                                          // создаем функцию с задержкой вызова\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","\n","  // new Promise - конструкция для отложенных вычислений\n","  // setTimeout позволяет вызвать функцию один раз через определённый интервал времени\n","}\n","\n","var data = new Promise(resolve=>{\n","recordButton.onclick = ()=>{      // при нажатии левой кнопкой мыши на кнопку \"Recording... press to stop\"\n","toggleRecording()                 // вызывается функция завершения аудиозаписи\n","\n","sleep(2000).then(() => {          // и после задержки 2000мс(2 сек)\n","  resolve(base64data.toString())  // полученные данные из формата base64 преобразовываем в строку\n","\n","});\n","\n","}\n","});\n","\n","</script>\n"]},"metadata":{}}]},{"cell_type":"code","source":["res = process_audio('recording1.wav', auth_token)\n","print('Результат распознавания:', res)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"viBF6-B9A72S","executionInfo":{"status":"ok","timestamp":1721046888860,"user_tz":-180,"elapsed":122999,"user":{"displayName":"Андрей Носков","userId":"00660409203221693156"}},"outputId":"3099b6b1-700f-44ca-8cb8-26a40d262cbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n"]},{"output_type":"stream","name":"stdout","text":["Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Could not understand segment for speaker SPEAKER_02\n","Результат распознавания: {'SPEAKER_02': ['микрофон запись идёт', 'проверка распознания текста', 'на этом'], 'SPEAKER_01': ['проверка работы программы persona 3'], 'SPEAKER_00': ['у нас был']}\n"]}]}]}